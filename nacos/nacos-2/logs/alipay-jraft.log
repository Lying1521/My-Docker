2022-12-07 11:31:21,654 INFO SPI service [com.alipay.sofa.jraft.JRaftServiceFactory - com.alipay.sofa.jraft.core.DefaultJRaftServiceFactory] loading.

2022-12-07 11:31:21,720 INFO SPI service [com.alipay.sofa.jraft.rpc.RaftRpcFactory - com.alipay.sofa.jraft.rpc.impl.GrpcRaftRpcFactory] loading.

2022-12-07 11:31:22,156 INFO SPI service [com.alipay.sofa.jraft.util.JRaftSignalHandler - com.alipay.sofa.jraft.NodeDescribeSignalHandler] loading.

2022-12-07 11:31:22,157 INFO SPI service [com.alipay.sofa.jraft.util.JRaftSignalHandler - com.alipay.sofa.jraft.NodeMetricsSignalHandler] loading.

2022-12-07 11:31:22,158 INFO SPI service [com.alipay.sofa.jraft.util.JRaftSignalHandler - com.alipay.sofa.jraft.ThreadPoolMetricsSignalHandler] loading.

2022-12-07 11:31:22,160 INFO SPI service [com.alipay.sofa.jraft.util.timer.RaftTimerFactory - com.alipay.sofa.jraft.util.timer.DefaultRaftTimerFactory] loading.

2022-12-07 11:31:22,167 INFO The number of active nodes increment to 1.

2022-12-07 11:31:22,386 INFO Starts FSMCaller successfully.

2022-12-07 11:31:22,394 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_persistent_service/snapshot.

2022-12-07 11:31:22,414 INFO Node <naming_persistent_service/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:31:22,417 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:31:22,417 INFO Start the RaftGroupService successfully.

2022-12-07 11:31:22,511 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.102:7848.

2022-12-07 11:31:22,512 WARN Channel in SHUTDOWN state: 10.11.0.102:7848.

2022-12-07 11:31:22,935 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:31:22,936 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:31:23,914 INFO The number of active nodes increment to 2.

2022-12-07 11:31:23,938 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.TimeoutException.

2022-12-07 11:31:23,939 ERROR Fail to connect peer 10.11.0.103:7848 to get leader for group naming_persistent_service.

2022-12-07 11:31:23,941 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:31:23,942 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:31:24,056 INFO Starts FSMCaller successfully.

2022-12-07 11:31:24,056 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_persistent_service_v2/snapshot.

2022-12-07 11:31:24,058 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:31:24,059 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:31:24,060 INFO Start the RaftGroupService successfully.

2022-12-07 11:31:24,083 INFO The number of active nodes increment to 3.

2022-12-07 11:31:24,187 INFO Starts FSMCaller successfully.

2022-12-07 11:31:24,187 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_instance_metadata/snapshot.

2022-12-07 11:31:24,188 INFO Node <naming_instance_metadata/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:31:24,189 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:31:24,190 INFO Start the RaftGroupService successfully.

2022-12-07 11:31:24,196 INFO The number of active nodes increment to 4.

2022-12-07 11:31:24,301 INFO Starts FSMCaller successfully.

2022-12-07 11:31:24,302 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_service_metadata/snapshot.

2022-12-07 11:31:24,303 INFO Node <naming_service_metadata/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:31:24,303 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:31:24,304 INFO Start the RaftGroupService successfully.

2022-12-07 11:31:27,572 INFO Node <naming_service_metadata/10.11.0.102:7848> received PreVoteRequest from 10.11.0.101:7848, term=1, currTerm=0, granted=true, requestLastLogId=LogId [index=0, term=0], lastLogId=LogId [index=0, term=0].

2022-12-07 11:31:27,583 INFO Node <naming_service_metadata/10.11.0.102:7848> received RequestVoteRequest from 10.11.0.101:7848, term=1, currTerm=0.

2022-12-07 11:31:27,593 INFO Node <naming_persistent_service/10.11.0.102:7848> term 0 start preVote.

2022-12-07 11:31:27,598 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:31:27,598 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 11:31:27,598 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:31:27,613 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_service_metadata/meta-data, term=1, votedFor=0.0.0.0:0, cost time=29 ms

2022-12-07 11:31:27,613 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:31:27,614 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 11:31:27,614 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:31:27,635 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_service_metadata/meta-data, term=1, votedFor=10.11.0.101:7848, cost time=20 ms

2022-12-07 11:31:27,682 INFO -Djraft.recyclers.maxCapacityPerThread: 4096.

2022-12-07 11:31:28,615 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 999707839ns. [buffered_nanos=999784632, waiting_for_connection].

2022-12-07 11:31:28,616 WARN Node <naming_persistent_service/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 11:31:28,618 INFO Node <naming_persistent_service/10.11.0.102:7848> received PreVoteResponse from 10.11.0.101:7848, term=0, granted=true.

2022-12-07 11:31:28,618 INFO Node <naming_persistent_service/10.11.0.102:7848> start vote and grant vote self, term=0.

2022-12-07 11:31:28,641 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=20 ms

2022-12-07 11:31:28,664 INFO Node <naming_persistent_service/10.11.0.102:7848> become leader of group, term=1, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:31:28,672 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower]@10.11.0.101:7848 is started

2022-12-07 11:31:28,678 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower]@10.11.0.103:7848 is started

2022-12-07 11:31:28,711 INFO onLeaderStart: term=1.

2022-12-07 11:31:29,180 WARN Node <naming_persistent_service/10.11.0.102:7848> RequestVote to 10.11.0.103:7848 error: Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception].

2022-12-07 11:31:29,270 INFO Node <naming_instance_metadata/10.11.0.102:7848> term 0 start preVote.

2022-12-07 11:31:29,272 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:31:29,272 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 11:31:29,272 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:31:29,282 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:31:29,283 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 11:31:29,283 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:31:29,398 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> received PreVoteRequest from 10.11.0.101:7848, term=1, currTerm=0, granted=true, requestLastLogId=LogId [index=0, term=0], lastLogId=LogId [index=0, term=0].

2022-12-07 11:31:29,404 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> received RequestVoteRequest from 10.11.0.101:7848, term=1, currTerm=0.

2022-12-07 11:31:29,430 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service_v2/meta-data, term=1, votedFor=0.0.0.0:0, cost time=25 ms

2022-12-07 11:31:29,446 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service_v2/meta-data, term=1, votedFor=10.11.0.101:7848, cost time=16 ms

2022-12-07 11:31:30,284 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 999737660ns. [buffered_nanos=999848297, waiting_for_connection].

2022-12-07 11:31:30,284 WARN Node <naming_instance_metadata/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 11:31:30,285 INFO Node <naming_instance_metadata/10.11.0.102:7848> received PreVoteResponse from 10.11.0.101:7848, term=0, granted=true.

2022-12-07 11:31:30,285 INFO Node <naming_instance_metadata/10.11.0.102:7848> start vote and grant vote self, term=0.

2022-12-07 11:31:30,306 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_instance_metadata/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=19 ms

2022-12-07 11:31:30,328 INFO Node <naming_instance_metadata/10.11.0.102:7848> become leader of group, term=1, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:31:30,328 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower]@10.11.0.101:7848 is started

2022-12-07 11:31:30,330 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower]@10.11.0.103:7848 is started

2022-12-07 11:31:30,356 INFO onLeaderStart: term=1.

2022-12-07 11:31:32,286 WARN Node <naming_instance_metadata/10.11.0.102:7848> RequestVote to 10.11.0.103:7848 error: Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception].

2022-12-07 11:31:41,645 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:31:42,146 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:44,766 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=20, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:31:46,770 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=20, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:47,285 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=30, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:47,788 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:31:49,287 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:31:49,290 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=30, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:49,788 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=40, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:51,789 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=40, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:52,290 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=50, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:53,291 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:31:54,293 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=50, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:31:54,792 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:31:54,795 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=60, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:39:20,238 INFO Connection disconnected: /10.11.0.101:55658

2022-12-07 11:39:20,242 INFO Destroyed peer request context for naming_service_metadata/PeerPair[10.11.0.102:7848 -> 10.11.0.101:7848]

2022-12-07 11:39:20,244 INFO Destroyed peer request context for naming_persistent_service_v2/PeerPair[10.11.0.102:7848 -> 10.11.0.101:7848]

2022-12-07 11:39:26,693 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> term 1 start preVote.

2022-12-07 11:39:26,693 INFO onStopFollowing: LeaderChangeContext [leaderId=10.11.0.101:7848, term=1, status=Status[ERAFTTIMEDOUT<10001>: Lost connection from leader 10.11.0.101:7848.]].

2022-12-07 11:39:26,695 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:39:26,695 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 11:39:26,696 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:39:26,875 INFO Node <naming_service_metadata/10.11.0.102:7848> received PreVoteRequest from 10.11.0.103:7848, term=2, currTerm=1, granted=true, requestLastLogId=LogId [index=1, term=1], lastLogId=LogId [index=1, term=1].

2022-12-07 11:39:26,882 INFO Node <naming_service_metadata/10.11.0.102:7848> received RequestVoteRequest from 10.11.0.103:7848, term=2, currTerm=1.

2022-12-07 11:39:26,883 INFO onStopFollowing: LeaderChangeContext [leaderId=10.11.0.101:7848, term=1, status=Status[EHIGHERTERMRESPONSE<10008>: Raft node receives higher term RequestVoteRequest.]].

2022-12-07 11:39:26,911 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_service_metadata/meta-data, term=2, votedFor=0.0.0.0:0, cost time=29 ms

2022-12-07 11:39:26,926 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_service_metadata/meta-data, term=2, votedFor=10.11.0.103:7848, cost time=14 ms

2022-12-07 11:39:27,696 ERROR Fail to connect 10.11.0.101:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 999869850ns. [buffered_nanos=999942991, waiting_for_connection].

2022-12-07 11:39:27,697 WARN Node <naming_persistent_service_v2/10.11.0.102:7848> channel init failed, address=10.11.0.101:7848.

2022-12-07 11:39:27,698 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:39:27,698 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:39:27,698 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 11:39:27,705 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> received PreVoteResponse from 10.11.0.103:7848, term=1, granted=true.

2022-12-07 11:39:27,706 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> start vote and grant vote self, term=1.

2022-12-07 11:39:27,737 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service_v2/meta-data, term=2, votedFor=10.11.0.102:7848, cost time=29 ms

2022-12-07 11:39:27,760 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> become leader of group, term=2, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:39:27,760 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower]@10.11.0.101:7848 is started

2022-12-07 11:39:27,761 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower]@10.11.0.103:7848 is started

2022-12-07 11:39:27,776 INFO onLeaderStart: term=2.

2022-12-07 11:39:32,707 WARN Node <naming_persistent_service_v2/10.11.0.102:7848> RequestVote to 10.11.0.101:7848 error: Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 4999948100ns. [buffered_nanos=5000008858, waiting_for_connection]].

2022-12-07 11:39:34,355 INFO Connection disconnected: /10.11.0.103:48544

2022-12-07 11:39:34,356 INFO Destroyed peer request context for naming_service_metadata/PeerPair[10.11.0.102:7848 -> 10.11.0.103:7848]

2022-12-07 11:39:38,719 WARN Node <naming_persistent_service/10.11.0.102:7848> steps down when alive nodes don't satisfy quorum, term=1, deadNodes=10.11.0.103:7848,10.11.0.101:7848, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848.

2022-12-07 11:39:38,720 INFO onLeaderStop: status=Status[ERAFTTIMEDOUT<10001>: Majority of the group dies: 2/3].

2022-12-07 11:39:38,721 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower] is going to quit

2022-12-07 11:39:38,723 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower] is going to quit

2022-12-07 11:44:51,304 INFO SPI service [com.alipay.sofa.jraft.JRaftServiceFactory - com.alipay.sofa.jraft.core.DefaultJRaftServiceFactory] loading.

2022-12-07 11:44:51,466 INFO SPI service [com.alipay.sofa.jraft.rpc.RaftRpcFactory - com.alipay.sofa.jraft.rpc.impl.GrpcRaftRpcFactory] loading.

2022-12-07 11:44:52,185 INFO SPI service [com.alipay.sofa.jraft.util.JRaftSignalHandler - com.alipay.sofa.jraft.NodeDescribeSignalHandler] loading.

2022-12-07 11:44:52,187 INFO SPI service [com.alipay.sofa.jraft.util.JRaftSignalHandler - com.alipay.sofa.jraft.NodeMetricsSignalHandler] loading.

2022-12-07 11:44:52,187 INFO SPI service [com.alipay.sofa.jraft.util.JRaftSignalHandler - com.alipay.sofa.jraft.ThreadPoolMetricsSignalHandler] loading.

2022-12-07 11:44:52,190 INFO SPI service [com.alipay.sofa.jraft.util.timer.RaftTimerFactory - com.alipay.sofa.jraft.util.timer.DefaultRaftTimerFactory] loading.

2022-12-07 11:44:52,196 INFO The number of active nodes increment to 1.

2022-12-07 11:44:52,415 INFO Starts FSMCaller successfully.

2022-12-07 11:44:52,423 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_persistent_service/snapshot.

2022-12-07 11:44:52,442 INFO Node <naming_persistent_service/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:44:52,444 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:44:52,445 INFO Start the RaftGroupService successfully.

2022-12-07 11:44:52,511 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.102:7848.

2022-12-07 11:44:52,512 WARN Channel in SHUTDOWN state: 10.11.0.102:7848.

2022-12-07 11:44:52,758 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:44:52,758 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:44:53,670 INFO The number of active nodes increment to 2.

2022-12-07 11:44:53,760 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.TimeoutException.

2022-12-07 11:44:53,760 ERROR Fail to connect peer 10.11.0.103:7848 to get leader for group naming_persistent_service.

2022-12-07 11:44:53,762 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:44:53,762 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:44:53,769 INFO Starts FSMCaller successfully.

2022-12-07 11:44:53,770 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_persistent_service_v2/snapshot.

2022-12-07 11:44:53,772 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:44:53,773 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:44:53,774 INFO Start the RaftGroupService successfully.

2022-12-07 11:44:53,796 INFO The number of active nodes increment to 3.

2022-12-07 11:44:53,894 INFO Starts FSMCaller successfully.

2022-12-07 11:44:53,894 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_instance_metadata/snapshot.

2022-12-07 11:44:53,895 INFO Node <naming_instance_metadata/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:44:53,896 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:44:53,896 INFO Start the RaftGroupService successfully.

2022-12-07 11:44:53,902 INFO The number of active nodes increment to 4.

2022-12-07 11:44:54,006 INFO Starts FSMCaller successfully.

2022-12-07 11:44:54,006 WARN No data for snapshot reader /home/nacos/data/protocol/raft/naming_service_metadata/snapshot.

2022-12-07 11:44:54,007 INFO Node <naming_service_metadata/10.11.0.102:7848> init, term=0, lastLogId=LogId [index=0, term=0], conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:44:54,008 WARN RPC server is not started in RaftGroupService.

2022-12-07 11:44:54,008 INFO Start the RaftGroupService successfully.

2022-12-07 11:44:57,482 INFO Node <naming_persistent_service/10.11.0.102:7848> received PreVoteRequest from 10.11.0.101:7848, term=1, currTerm=0, granted=true, requestLastLogId=LogId [index=0, term=0], lastLogId=LogId [index=0, term=0].

2022-12-07 11:44:57,492 INFO Node <naming_persistent_service/10.11.0.102:7848> received RequestVoteRequest from 10.11.0.101:7848, term=1, currTerm=0.

2022-12-07 11:44:57,528 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service/meta-data, term=1, votedFor=0.0.0.0:0, cost time=35 ms

2022-12-07 11:44:57,543 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service/meta-data, term=1, votedFor=10.11.0.101:7848, cost time=14 ms

2022-12-07 11:44:57,585 INFO -Djraft.recyclers.maxCapacityPerThread: 4096.

2022-12-07 11:44:58,834 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> term 0 start preVote.

2022-12-07 11:44:58,836 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:44:58,836 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 11:44:58,837 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:44:58,851 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:44:58,851 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 11:44:58,852 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:44:59,005 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception.

2022-12-07 11:44:59,006 WARN Node <naming_persistent_service_v2/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 11:44:59,009 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> received PreVoteResponse from 10.11.0.101:7848, term=0, granted=true.

2022-12-07 11:44:59,009 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> start vote and grant vote self, term=0.

2022-12-07 11:44:59,012 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception.

2022-12-07 11:44:59,012 WARN Node <naming_persistent_service_v2/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 11:44:59,033 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service_v2/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=21 ms

2022-12-07 11:44:59,055 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> become leader of group, term=1, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:44:59,062 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower]@10.11.0.101:7848 is started

2022-12-07 11:44:59,069 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception.

2022-12-07 11:44:59,069 ERROR Fail to init sending channel to 10.11.0.103:7848.

2022-12-07 11:44:59,087 ERROR Fail to start replicator to peer=10.11.0.103:7848, replicatorType=Follower.

2022-12-07 11:44:59,088 ERROR Fail to add a replicator, peer=10.11.0.103:7848.

2022-12-07 11:44:59,114 INFO onLeaderStart: term=1.

2022-12-07 11:44:59,222 INFO Node <naming_instance_metadata/10.11.0.102:7848> term 0 start preVote.

2022-12-07 11:44:59,224 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:44:59,224 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:44:59,224 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 11:44:59,232 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:44:59,232 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 11:44:59,232 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:44:59,563 INFO Node <naming_service_metadata/10.11.0.102:7848> term 0 start preVote.

2022-12-07 11:44:59,566 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 11:44:59,566 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 11:44:59,568 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 11:44:59,589 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 11:44:59,589 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 11:44:59,589 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 11:45:00,233 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 999773010ns. [buffered_nanos=999897172, waiting_for_connection].

2022-12-07 11:45:00,233 WARN Node <naming_instance_metadata/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 11:45:00,234 INFO Node <naming_instance_metadata/10.11.0.102:7848> received PreVoteResponse from 10.11.0.101:7848, term=0, granted=true.

2022-12-07 11:45:00,234 INFO Node <naming_instance_metadata/10.11.0.102:7848> start vote and grant vote self, term=0.

2022-12-07 11:45:00,255 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_instance_metadata/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=19 ms

2022-12-07 11:45:00,279 INFO Node <naming_instance_metadata/10.11.0.102:7848> become leader of group, term=1, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:45:00,280 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower]@10.11.0.101:7848 is started

2022-12-07 11:45:00,282 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower]@10.11.0.103:7848 is started

2022-12-07 11:45:00,311 INFO onLeaderStart: term=1.

2022-12-07 11:45:00,591 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.ExecutionException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: deadline exceeded after 999558539ns. [buffered_nanos=999649091, waiting_for_connection].

2022-12-07 11:45:00,592 WARN Node <naming_service_metadata/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 11:45:00,592 INFO Node <naming_service_metadata/10.11.0.102:7848> received PreVoteResponse from 10.11.0.101:7848, term=0, granted=true.

2022-12-07 11:45:00,592 INFO Node <naming_service_metadata/10.11.0.102:7848> start vote and grant vote self, term=0.

2022-12-07 11:45:00,613 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_service_metadata/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=20 ms

2022-12-07 11:45:00,642 INFO Node <naming_service_metadata/10.11.0.102:7848> become leader of group, term=1, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848, oldConf=.

2022-12-07 11:45:00,643 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower]@10.11.0.101:7848 is started

2022-12-07 11:45:00,644 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower]@10.11.0.103:7848 is started

2022-12-07 11:45:00,670 INFO onLeaderStart: term=1.

2022-12-07 11:45:01,590 INFO Replicator=Replicator [state=null, statInfo=<running=null, firstLogIndex=0, lastLogIncluded=0, lastLogIndex=0, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower]@10.11.0.103:7848 is started

2022-12-07 11:45:02,128 WARN Node <naming_service_metadata/10.11.0.102:7848> RequestVote to 10.11.0.103:7848 error: Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception].

2022-12-07 11:45:02,128 WARN Node <naming_instance_metadata/10.11.0.102:7848> RequestVote to 10.11.0.103:7848 error: Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception].

2022-12-07 11:45:11,986 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:11,986 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:11,986 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:14,488 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=20, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:15,612 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=20, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:15,612 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=20, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:16,138 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:45:16,990 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=30, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:18,115 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:45:18,115 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=30, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:18,118 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=30, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:18,616 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:45:19,494 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=40, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:20,618 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=40, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:20,620 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=40, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:21,496 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:45:21,999 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=50, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:23,121 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=50, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:23,122 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=50, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:39,002 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=60, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 4999930900ns. [buffered_nanos=5000045858, waiting_for_connection]]

2022-12-07 11:45:41,125 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=60, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499862900ns. [buffered_nanos=2499938761, waiting_for_connection]]

2022-12-07 11:45:44,126 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=60, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499916530ns. [buffered_nanos=2499970091, waiting_for_connection]]

2022-12-07 11:45:53,965 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=70, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:45:53,993 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:45:54,466 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=70, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:45:54,966 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:45:56,966 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=70, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499914331ns. [buffered_nanos=2499971222, waiting_for_connection]]

2022-12-07 11:45:58,086 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=80, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:00,706 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=90, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:01,206 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:06,588 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=80, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:06,968 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=80, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:10,066 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=90, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:10,566 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=90, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:12,567 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=100, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:12,837 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=100, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:13,067 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:13,067 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:13,069 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=100, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:17,807 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=110, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:22,055 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=120, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:46:23,056 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:25,166 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=110, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:46:25,665 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=110, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:29,286 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=120, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:30,287 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=120, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:31,405 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=130, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:46:31,788 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:31,790 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=130, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:32,907 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=130, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:33,908 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:37,645 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=140, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:46:38,145 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=140, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:40,648 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=150, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:41,650 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:44,033 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=140, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:45,149 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=150, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:48,007 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=150, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:49,007 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=160, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:49,895 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=160, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499934860ns. [buffered_nanos=2500008582, waiting_for_connection]]

2022-12-07 11:46:50,508 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:50,509 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=160, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:51,009 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:46:56,365 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=170, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:46:56,865 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=170, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:46:59,367 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=180, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:00,868 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:02,605 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=170, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:05,725 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=190, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:06,226 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=180, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:06,726 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=180, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:08,727 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=190, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:09,228 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=190, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:10,228 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:12,966 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:15,096 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=200, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:15,596 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=200, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:18,098 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=210, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:20,099 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:20,967 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=200, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499911520ns. [buffered_nanos=2500019792, waiting_for_connection]]

2022-12-07 11:47:24,326 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=220, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499982200ns. [buffered_nanos=2500065527, waiting_for_connection]]

2022-12-07 11:47:24,946 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=210, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:25,099 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=210, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:27,447 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=220, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:28,448 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:29,566 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=220, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:31,828 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=230, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:34,806 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=230, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:35,306 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:35,307 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=240, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:36,925 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=230, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:37,308 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:40,045 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=250, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:44,666 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=240, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:46,285 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=240, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:47,167 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=250, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:49,905 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=250, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:50,405 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:52,406 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=260, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:52,525 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=260, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:47:52,907 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:47:55,028 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=270, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:47:55,525 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=260, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499928360ns. [buffered_nanos=2500027271, waiting_for_connection]]

2022-12-07 11:48:00,031 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=280, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:00,266 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:04,647 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=270, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499931491ns. [buffered_nanos=2500020566, waiting_for_connection]]

2022-12-07 11:48:05,505 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=270, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:08,007 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=280, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:09,626 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=280, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:11,397 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=290, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:12,127 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=290, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:13,256 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:13,257 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=290, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:14,876 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:15,377 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=300, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:17,879 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=310, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:18,380 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:20,605 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=300, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:48:26,845 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=300, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:48:29,347 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=310, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:29,965 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=320, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:48:29,965 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=310, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:48:31,848 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=320, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:31,850 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:32,467 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=320, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:34,086 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=330, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:36,589 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=340, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:37,090 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:37,206 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:39,325 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=330, error=Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: io exception]

2022-12-07 11:48:42,587 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=330, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:43,326 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=350, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:44,327 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=340, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:45,089 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=340, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:45,828 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=360, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:46,829 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=350, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:47,591 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:47,592 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=350, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:47,829 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:47,830 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 11:48:48,331 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=370, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:49,332 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=360, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:50,094 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=360, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:50,833 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=380, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:51,834 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=370, error=Status[EINTERNAL<1004>: Check connection[10.11.0.103:7848] fail and try to create new one]

2022-12-07 11:48:52,855 WARN Heartbeat to peer 10.11.0.103:7848 failure, try to send a probe request.

2022-12-07 11:48:52,962 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 12:00:40,311 INFO Deleting snapshot /home/nacos/data/protocol/raft/naming_persistent_service/snapshot/snapshot_1.

2022-12-07 12:00:40,311 INFO Renaming /home/nacos/data/protocol/raft/naming_persistent_service/snapshot/temp to /home/nacos/data/protocol/raft/naming_persistent_service/snapshot/snapshot_1.

2022-12-07 12:00:45,716 INFO Deleting snapshot /home/nacos/data/protocol/raft/naming_instance_metadata/snapshot/snapshot_1.

2022-12-07 12:00:45,716 INFO Renaming /home/nacos/data/protocol/raft/naming_instance_metadata/snapshot/temp to /home/nacos/data/protocol/raft/naming_instance_metadata/snapshot/snapshot_1.

2022-12-07 12:04:02,902 INFO Deleting snapshot /home/nacos/data/protocol/raft/naming_service_metadata/snapshot/snapshot_1.

2022-12-07 12:04:02,902 INFO Renaming /home/nacos/data/protocol/raft/naming_service_metadata/snapshot/temp to /home/nacos/data/protocol/raft/naming_service_metadata/snapshot/snapshot_1.

2022-12-07 12:08:53,569 INFO Deleting snapshot /home/nacos/data/protocol/raft/naming_persistent_service_v2/snapshot/snapshot_1.

2022-12-07 12:08:53,570 INFO Renaming /home/nacos/data/protocol/raft/naming_persistent_service_v2/snapshot/temp to /home/nacos/data/protocol/raft/naming_persistent_service_v2/snapshot/snapshot_1.

2022-12-07 13:32:04,601 INFO Connection disconnected: /10.11.0.103:51532

2022-12-07 13:32:09,622 WARN Channel[10.11.0.103:7848] in TRANSIENT_FAILURE state 21 times, will be reset connect backoff.

2022-12-07 13:32:12,625 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499961870ns. [buffered_nanos=2500404932, waiting_for_connection]]

2022-12-07 13:32:12,680 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499965410ns. [buffered_nanos=2500084353, waiting_for_connection]]

2022-12-07 13:32:13,906 INFO Node <naming_persistent_service/10.11.0.102:7848> start vote and grant vote self, term=1.

2022-12-07 13:32:13,909 INFO Destroyed peer request context for naming_persistent_service/PeerPair[10.11.0.102:7848 -> 10.11.0.101:7848]

2022-12-07 13:32:13,926 INFO onStopFollowing: LeaderChangeContext [leaderId=10.11.0.101:7848, term=1, status=Status[ERAFTTIMEDOUT<10001>: A follower's leader_id is reset to NULL as it begins to request_vote.]].

2022-12-07 13:32:13,936 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.101:7848.

2022-12-07 13:32:13,936 INFO Peer 10.11.0.101:7848 is connected.

2022-12-07 13:32:13,936 WARN Channel in SHUTDOWN state: 10.11.0.101:7848.

2022-12-07 13:32:13,962 WARN Channel in TRANSIENT_FAILURE state: 10.11.0.103:7848.

2022-12-07 13:32:13,962 INFO Peer 10.11.0.103:7848 is connected.

2022-12-07 13:32:13,962 WARN Channel in SHUTDOWN state: 10.11.0.103:7848.

2022-12-07 13:32:13,962 WARN Node <naming_persistent_service/10.11.0.102:7848> RequestVote to 10.11.0.101:7848 error: Status[ENOENT<1012>: Peer id not found: 10.11.0.101:7848, group: naming_persistent_service].

2022-12-07 13:32:14,215 INFO Connection disconnected: /10.11.0.101:57038

2022-12-07 13:32:14,968 ERROR Fail to connect 10.11.0.103:7848, remoting exception: java.util.concurrent.TimeoutException.

2022-12-07 13:32:14,968 WARN Node <naming_persistent_service/10.11.0.102:7848> channel init failed, address=10.11.0.103:7848.

2022-12-07 13:32:15,079 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service/meta-data, term=2, votedFor=10.11.0.102:7848, cost time=110 ms

2022-12-07 13:32:15,080 INFO Node <naming_persistent_service/10.11.0.102:7848> received TimeoutNowRequest from 10.11.0.101:7848, term=1.

2022-12-07 13:32:15,123 WARN Fail to issue RPC to 10.11.0.103:7848, consecutiveErrorTimes=10, error=Status[EINTERNAL<1004>: RPC exception:DEADLINE_EXCEEDED: deadline exceeded after 2499928640ns. [buffered_nanos=2499984876, waiting_for_connection]]

2022-12-07 13:32:19,332 WARN Node <naming_instance_metadata/10.11.0.102:7848> steps down when alive nodes don't satisfy quorum, term=1, deadNodes=10.11.0.103:7848,10.11.0.101:7848, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848.

2022-12-07 13:32:19,332 WARN Node <naming_service_metadata/10.11.0.102:7848> steps down when alive nodes don't satisfy quorum, term=1, deadNodes=10.11.0.103:7848,10.11.0.101:7848, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848.

2022-12-07 13:32:19,338 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower] is going to quit

2022-12-07 13:32:19,338 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower] is going to quit

2022-12-07 13:32:19,340 WARN Node <naming_persistent_service_v2/10.11.0.102:7848> steps down when alive nodes don't satisfy quorum, term=1, deadNodes=10.11.0.103:7848,10.11.0.101:7848, conf=10.11.0.102:7848,10.11.0.103:7848,10.11.0.101:7848.

2022-12-07 13:32:19,346 INFO onLeaderStop: status=Status[ERAFTTIMEDOUT<10001>: Majority of the group dies: 2/3].

2022-12-07 13:32:19,347 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.101:7848, type=Follower] is going to quit

2022-12-07 13:32:19,351 INFO onLeaderStop: status=Status[ERAFTTIMEDOUT<10001>: Majority of the group dies: 2/3].

2022-12-07 13:32:19,353 INFO onLeaderStop: status=Status[ERAFTTIMEDOUT<10001>: Majority of the group dies: 2/3].

2022-12-07 13:32:19,357 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower] is going to quit

2022-12-07 13:32:19,357 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=1, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower] is going to quit

2022-12-07 13:32:19,357 INFO Replicator Replicator [state=Probe, statInfo=<running=IDLE, firstLogIndex=2, lastLogIncluded=0, lastLogIndex=1, lastTermIncluded=0>, peerId=10.11.0.103:7848, type=Follower] is going to quit

2022-12-07 13:32:19,928 WARN Candidate node <naming_persistent_service/10.11.0.102:7848> term 2 steps down when election reaching vote timeout: fail to get quorum vote-granted.

2022-12-07 13:32:19,929 INFO Node <naming_persistent_service/10.11.0.102:7848> term 2 start preVote.

2022-12-07 13:32:20,413 INFO Node <naming_service_metadata/10.11.0.102:7848> shutdown, currTerm=1 state=STATE_FOLLOWER.

2022-12-07 13:32:20,435 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_service_metadata/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=19 ms

2022-12-07 13:32:20,435 INFO Shutting down FSMCaller...

2022-12-07 13:32:20,436 INFO onShutdown.

2022-12-07 13:32:20,437 INFO Shutdown managed channel: 10.11.0.101:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=47, target=10.11.0.101:7848}}.

2022-12-07 13:32:20,642 INFO Shutdown managed channel: 10.11.0.103:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=51, target=10.11.0.103:7848}}.

2022-12-07 13:32:20,858 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-ElectionTimer-<naming_service_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:20,860 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-VoteTimer-<naming_service_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:20,861 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=2500, name='JRaft-StepDownTimer-<naming_service_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:20,863 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=1800000, name='JRaft-SnapshotTimer-<naming_service_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:20,907 INFO Node <naming_service_metadata/10.11.0.102:7848> shutdown, currTerm=1 state=STATE_SHUTTING.

2022-12-07 13:32:20,913 INFO The number of active nodes decrement to 3.

2022-12-07 13:32:20,914 INFO Stop the RaftGroupService successfully.

2022-12-07 13:32:20,925 INFO ThreadPool is terminated: JRaft-RPC-Processor, com.alipay.sofa.jraft.util.MetricThreadPoolExecutor@b774ce4[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 3].

2022-12-07 13:32:20,925 INFO Node <naming_persistent_service/10.11.0.102:7848> shutdown, currTerm=2 state=STATE_FOLLOWER.

2022-12-07 13:32:20,925 INFO ThreadPool is terminated: JRaft-Node-ScheduleThreadPool, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@732901b3[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 25523].

2022-12-07 13:32:20,949 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service/meta-data, term=2, votedFor=10.11.0.102:7848, cost time=19 ms

2022-12-07 13:32:20,949 INFO Shutting down FSMCaller...

2022-12-07 13:32:20,949 INFO onShutdown.

2022-12-07 13:32:20,950 INFO Shutdown managed channel: 10.11.0.101:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=316, target=10.11.0.101:7848}}.

2022-12-07 13:32:21,151 INFO Shutdown managed channel: 10.11.0.103:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=324, target=10.11.0.103:7848}}.

2022-12-07 13:32:21,154 WARN Node <naming_persistent_service/10.11.0.102:7848> PreVote to 10.11.0.101:7848 error: Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: Channel shutdownNow invoked].

2022-12-07 13:32:21,354 WARN Node <naming_persistent_service/10.11.0.102:7848> PreVote to 10.11.0.103:7848 error: Status[EINTERNAL<1004>: RPC exception:UNAVAILABLE: Channel shutdownNow invoked].

2022-12-07 13:32:21,357 INFO ThreadPool is terminated: JRaft-Node-ScheduleThreadPool, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@11cc7431[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0].

2022-12-07 13:32:21,357 INFO ThreadPool is terminated: JRaft-RPC-Processor, com.alipay.sofa.jraft.util.MetricThreadPoolExecutor@69c6850b[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 3].

2022-12-07 13:32:21,357 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-ElectionTimer-<naming_persistent_service/10.11.0.102:7848>'}.

2022-12-07 13:32:21,357 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-VoteTimer-<naming_persistent_service/10.11.0.102:7848>'}.

2022-12-07 13:32:21,358 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=2500, name='JRaft-StepDownTimer-<naming_persistent_service/10.11.0.102:7848>'}.

2022-12-07 13:32:21,358 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=1800000, name='JRaft-SnapshotTimer-<naming_persistent_service/10.11.0.102:7848>'}.

2022-12-07 13:32:21,362 INFO Node <naming_persistent_service/10.11.0.102:7848> shutdown, currTerm=2 state=STATE_SHUTTING.

2022-12-07 13:32:21,363 INFO Stop the RaftGroupService successfully.

2022-12-07 13:32:21,363 INFO Node <naming_instance_metadata/10.11.0.102:7848> shutdown, currTerm=1 state=STATE_FOLLOWER.

2022-12-07 13:32:21,364 INFO The number of active nodes decrement to 2.

2022-12-07 13:32:21,578 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_instance_metadata/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=215 ms

2022-12-07 13:32:21,579 INFO Shutting down FSMCaller...

2022-12-07 13:32:21,579 INFO onShutdown.

2022-12-07 13:32:21,580 INFO Shutdown managed channel: 10.11.0.101:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=39, target=10.11.0.101:7848}}.

2022-12-07 13:32:21,781 INFO Shutdown managed channel: 10.11.0.103:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=43, target=10.11.0.103:7848}}.

2022-12-07 13:32:22,003 INFO The number of active nodes decrement to 1.

2022-12-07 13:32:22,003 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-ElectionTimer-<naming_instance_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:22,004 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-VoteTimer-<naming_instance_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:22,004 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=2500, name='JRaft-StepDownTimer-<naming_instance_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:22,005 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=1800000, name='JRaft-SnapshotTimer-<naming_instance_metadata/10.11.0.102:7848>'}.

2022-12-07 13:32:22,008 INFO ThreadPool is terminated: JRaft-RPC-Processor, com.alipay.sofa.jraft.util.MetricThreadPoolExecutor@18f4956f[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 3].

2022-12-07 13:32:22,008 INFO Node <naming_instance_metadata/10.11.0.102:7848> shutdown, currTerm=1 state=STATE_SHUTTING.

2022-12-07 13:32:22,008 INFO ThreadPool is terminated: JRaft-Node-ScheduleThreadPool, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@354ec8a7[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 25528].

2022-12-07 13:32:22,009 INFO Stop the RaftGroupService successfully.

2022-12-07 13:32:22,009 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> shutdown, currTerm=1 state=STATE_FOLLOWER.

2022-12-07 13:32:22,043 INFO Save raft meta, path=/home/nacos/data/protocol/raft/naming_persistent_service_v2/meta-data, term=1, votedFor=10.11.0.102:7848, cost time=34 ms

2022-12-07 13:32:22,044 INFO Shutting down FSMCaller...

2022-12-07 13:32:22,044 INFO onShutdown.

2022-12-07 13:32:22,045 INFO Shutdown managed channel: 10.11.0.101:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=30, target=10.11.0.101:7848}}.

2022-12-07 13:32:22,246 INFO Shutdown managed channel: 10.11.0.103:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=34, target=10.11.0.103:7848}}.

2022-12-07 13:32:22,468 INFO The number of active nodes decrement to 0.

2022-12-07 13:32:22,471 INFO ThreadPool is terminated: JRaft-RPC-Processor, com.alipay.sofa.jraft.util.MetricThreadPoolExecutor@4159a182[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2].

2022-12-07 13:32:22,472 INFO ThreadPool is terminated: JRaft-Global-ElectionTimer, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@425a7036[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1181].

2022-12-07 13:32:22,473 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-ElectionTimer-<naming_persistent_service_v2/10.11.0.102:7848>'}.

2022-12-07 13:32:22,473 INFO ThreadPool is terminated: JRaft-Node-ScheduleThreadPool, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@65f4b4e7[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 25541].

2022-12-07 13:32:22,475 INFO ThreadPool is terminated: JRaft-Global-VoteTimer, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@5bc5639[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 4].

2022-12-07 13:32:22,475 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=5000, name='JRaft-VoteTimer-<naming_persistent_service_v2/10.11.0.102:7848>'}.

2022-12-07 13:32:22,477 INFO ThreadPool is terminated: JRaft-Global-StepDownTimer, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@1f2416ae[Shutting down, pool size = 9, active threads = 0, queued tasks = 0, completed tasks = 7725].

2022-12-07 13:32:22,477 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=2500, name='JRaft-StepDownTimer-<naming_persistent_service_v2/10.11.0.102:7848>'}.

2022-12-07 13:32:22,481 INFO ThreadPool is terminated: JRaft-Global-SnapshotTimer, com.alipay.sofa.jraft.util.MetricScheduledThreadPoolExecutor@29a90f8e[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 14].

2022-12-07 13:32:22,481 INFO Destroy timer: RepeatedTimer{timeout=null, stopped=true, running=false, destroyed=true, invoking=false, timeoutMs=1800000, name='JRaft-SnapshotTimer-<naming_persistent_service_v2/10.11.0.102:7848>'}.

2022-12-07 13:32:22,483 INFO Node <naming_persistent_service_v2/10.11.0.102:7848> shutdown, currTerm=1 state=STATE_SHUTTING.

2022-12-07 13:32:22,483 INFO Stop the RaftGroupService successfully.

2022-12-07 13:32:22,487 INFO Shutdown managed channel: 10.11.0.101:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=21, target=10.11.0.101:7848}}.

2022-12-07 13:32:22,688 INFO Shutdown managed channel: 10.11.0.102:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=5, target=10.11.0.102:7848}}.

2022-12-07 13:32:22,690 INFO Connection disconnected: /10.11.0.102:49220

2022-12-07 13:32:22,690 INFO Shutdown managed channel: 10.11.0.103:7848, ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=10, target=10.11.0.103:7848}}.

2022-12-07 13:32:22,897 INFO ThreadPool is terminated: JRaft-RPC-Processor, com.alipay.sofa.jraft.util.MetricThreadPoolExecutor@26051c8e[Shutting down, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 6796].

